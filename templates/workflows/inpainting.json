{
  "45": {
    "inputs": {
      "ckpt_name": "juggernaut_aftermath.safetensors",
      "config_name": "Default",
      "vae_name": "juggernaut_TRCVAE.safetensors",
      "clip_skip": -1,
      "lora1_name": "lcm_sd15_pytorch_lora_weights.safetensors",
      "lora1_model_strength": 1,
      "lora1_clip_strength": 1,
      "lora2_name": "None",
      "lora2_model_strength": 1,
      "lora2_clip_strength": 1,
      "lora3_name": "None",
      "lora3_model_strength": 1,
      "lora3_clip_strength": 1,
      "positive": [
        "48",
        0
      ],
      "positive_token_normalization": "none",
      "positive_weight_interpretation": "comfy",
      "negative": [
        "47",
        0
      ],
      "negative_token_normalization": "none",
      "negative_weight_interpretation": "comfy",
      "empty_latent_width": [
        "58",
        2
      ],
      "empty_latent_height": [
        "58",
        1
      ],
      "batch_size": 1,
      "seed": 0
    },
    "show": false,
    "title": "pipeLoader",
    "class_type": "ttN pipeLoader"
  },
  "46": {
    "inputs": {
      "lora_name": "None",
      "lora_model_strength": 1,
      "lora_clip_strength": 1,
      "upscale_method": "None",
      "factor": 2,
      "crop": "disabled",
      "sampler_state": "Sample",
      "add_noise": "enable",
      "steps": 6,
      "cfg": 1,
      "sampler_name": "lcm",
      "scheduler": "sgm_uniform",
      "start_at_step": 0,
      "end_at_step": 4,
      "return_with_leftover_noise": "enable",
      "image_output": "Preview",
      "save_prefix": "ComfyUI",
      "noise_seed": [
        "80",
        0
      ],
      "pipe": [
        "45",
        0
      ],
      "optional_model": [
        "69",
        0
      ],
      "optional_positive": [
        "54",
        0
      ]
    },
    "show": false,
    "title": "pipeKSamplerAdvanced",
    "class_type": "ttN pipeKSamplerAdvanced"
  },
  "47": {
    "inputs": {
      "String": "embedding:JuggernautNegative-neg"
    },
    "show": true,
    "title": "Negative",
    "class_type": "String"
  },
  "48": {
    "inputs": {
      "String": "portrait of a man, blurred crowd in the background"
    },
    "show": true,
    "title": "Positive",
    "class_type": "String"
  },
  "54": {
    "inputs": {
      "strength": [
        "91",
        0
      ],
      "conditioning": [
        "45",
        2
      ],
      "control_net": [
        "55",
        0
      ],
      "image": [
        "57",
        0
      ]
    },
    "show": false,
    "title": "Apply ControlNet",
    "class_type": "ControlNetApply"
  },
  "55": {
    "inputs": {
      "control_net_name": "control_v11p_sd15_inpaint.pth"
    },
    "show": false,
    "title": "Load ControlNet Model",
    "class_type": "ControlNetLoader"
  },
  "57": {
    "inputs": {
      "image": [
        "59",
        0
      ],
      "mask": [
        "59",
        1
      ]
    },
    "show": false,
    "title": "Inpaint Preprocessor",
    "class_type": "InpaintPreprocessor"
  },
  "58": {
    "inputs": {
      "value": [
        "59",
        0
      ]
    },
    "show": false,
    "title": "ImpactImageInfo",
    "class_type": "ImpactImageInfo"
  },
  "59": {
    "inputs": {
      "image": "BaseImage_ue8cn.png",
      "value": 512,
      "upload": "image"
    },
    "show": true,
    "title": "BaseImage",
    "class_type": "LoadResizeImageMask512"
  },
  "63": {
    "inputs": {
      "lora_name": "None",
      "lora_model_strength": 1,
      "lora_clip_strength": 1,
      "upscale_method": "None",
      "factor": 2,
      "crop": "disabled",
      "sampler_state": "Sample",
      "add_noise": "enable",
      "steps": 6,
      "cfg": 1,
      "sampler_name": "lcm",
      "scheduler": "sgm_uniform",
      "start_at_step": 3,
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable",
      "image_output": "Preview",
      "save_prefix": "ComfyUI",
      "noise_seed": [
        "46",
        8
      ],
      "pipe": [
        "46",
        0
      ],
      "optional_latent": [
        "46",
        4
      ]
    },
    "show": false,
    "title": "pipeKSamplerAdvanced",
    "class_type": "ttN pipeKSamplerAdvanced"
  },
  "69": {
    "inputs": {
      "sampling": "lcm",
      "zsnr": false,
      "model": [
        "70",
        0
      ]
    },
    "show": false,
    "title": "ModelSamplingDiscrete",
    "class_type": "ModelSamplingDiscrete"
  },
  "70": {
    "inputs": {
      "weight": 0.8,
      "noise": 0.33,
      "weight_type": "channel penalty",
      "start_at": 0,
      "end_at": 1,
      "ipadapter": [
        "71",
        0
      ],
      "clip_vision": [
        "73",
        0
      ],
      "image": [
        "72",
        0
      ],
      "model": [
        "93",
        0
      ]
    },
    "show": false,
    "title": "Apply IPAdapter",
    "class_type": "IPAdapterApply"
  },
  "71": {
    "inputs": {
      "ipadapter_file": "ip-adapter-plus_sd15.bin"
    },
    "show": false,
    "title": "Load IPAdapter Model",
    "class_type": "IPAdapterModelLoader"
  },
  "72": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "center",
      "sharpening": 0,
      "image": [
        "74",
        0
      ]
    },
    "show": false,
    "title": "Prepare Image For Clip Vision",
    "class_type": "PrepImageForClipVision"
  },
  "73": {
    "inputs": {
      "clip_name": "model_sd15_ipadapter_plus_clipvision.safetensors"
    },
    "show": false,
    "title": "Load CLIP Vision",
    "class_type": "CLIPVisionLoader"
  },
  "74": {
    "inputs": {
      "image": "bgimage_ (15).jpg",
      "upload": "image"
    },
    "show": true,
    "title": "BGImage",
    "class_type": "LoadImage"
  },
  "80": {
    "inputs": {
      "seed": 8731190471619643
    },
    "show": true,
    "title": "Seed",
    "class_type": "ttN seed"
  },
  "87": {
    "inputs": {
      "filename_prefix": "__inpainting",
      "images": [
        "63",
        7
      ]
    },
    "show": false,
    "title": "Save Image",
    "class_type": "SaveImage"
  },
  "91": {
    "inputs": {
      "Value": 1
    },
    "show": true,
    "title": "Painting Strength",
    "class_type": "Float"
  },
  "93": {
    "inputs": {
      "lora_name": "more_details.safetensors",
      "strength_model": 1,
      "strength_clip": 1,
      "model": [
        "45",
        1
      ],
      "clip": [
        "45",
        6
      ]
    },
    "show": false,
    "title": "Load LoRA",
    "class_type": "LoraLoader"
  },
  "95": {
    "inputs": {
      "force_resize_width": 0,
      "force_resize_height": 0,
      "image": [
        "63",
        7
      ],
      "mask": [
        "99",
        0
      ]
    },
    "show": false,
    "title": "Cut By Mask",
    "class_type": "Cut By Mask"
  },
  "96": {
    "inputs": {
      "mask": [
        "59",
        1
      ]
    },
    "show": false,
    "title": "Convert Mask to Image",
    "class_type": "MaskToImage"
  },
  "99": {
    "inputs": {
      "image": [
        "96",
        0
      ]
    },
    "show": false,
    "title": "Invert Image",
    "class_type": "ImageInvert"
  },
  "100": {
    "inputs": {
      "filename_prefix": "__inpaintingmasked",
      "images": [
        "95",
        0
      ]
    },
    "show": false,
    "title": "Save Image",
    "class_type": "SaveImage"
  }
}